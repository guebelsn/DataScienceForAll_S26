{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"finalProject.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project: Regression Inference & Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the Final Project for Data Science for All!  This is the final project for our course and with this project you will get to explore a dataset of your choice. By the end of the project, you will have some experience with:\n",
    "\n",
    "1. Finding a dataset of interest.\n",
    "2. Performing some exploratory analysis using linear regression and inference.\n",
    "3. Building a k-nearest-neighbors classifier.\n",
    "4. Testing a classifier on data.\n",
    "\n",
    "### Logistics\n",
    "\n",
    "**Rules.** Don't share your code with anybody. You are welcome to discuss your project with other students, but don't share your project details or copy a project from the internet. This project should be YOUR OWN (code, etc.). If you do base your project on something you learned online or through a generative AI tool such as ChatGPT, make sure to check with your instructor before getting started and reference your sources as part of this project. The experience of solving the problems in this project will prepare you for the final exam (and life). During the final lab session, you will have a chance to share with the whole class.\n",
    "\n",
    "**Support.** You are not alone! Come to lab hours, tutoring hours, office hours, and talk to your classmates. If you're ever feeling overwhelmed or don't know how to make progress, we are here to help! Don't hesitate to send an email. \n",
    "\n",
    "**Advice.** Develop your project incrementally. To perform a complicated table manipulation, break it up into steps, perform each step on a different line, give a new name to each result, and check that each intermediate result is what you expect. Don't hesitate to add more names/variables or functions if this helps with your analysis or classifier development. Also, please be sure to not re-assign variables throughout the notebook! For example, if you use max_temperature in your answer to one question, do not reassign it later on.\n",
    "\n",
    "To get started, load `datascience`, `numpy`, and `plots`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading**: \n",
    "\n",
    "* [Inference for Regression](https://www.inferentialthinking.com/chapters/16/Inference_for_Regression.html)\n",
    "\n",
    "* [Classification](https://www.inferentialthinking.com/chapters/17/Classification.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-11T12:12:38.902167Z",
     "start_time": "2018-04-11T12:12:38.883124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Don't change this cell; just run it. If you need additional libraries for your project, you can add them to this cell.\n",
    "\n",
    "import numpy as np\n",
    "from datascience import *\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "from matplotlib import patches\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Picking a Dataset\n",
    "\n",
    "In this project, you are exploring a dataset of your choice. \n",
    "The dataset should be large enough: multiple individuals (rows) with multiple attributes (columns) such that we can try to make a prediction based on the known information in this dataset using linear regression and/or classification.\n",
    "In this first section you will:\n",
    "- find a data set that you are interested in\n",
    "- record the source of where you found it\n",
    "- save it as a .csv file in the same folder as your jupyter notebook.\n",
    "- make sure you can read it in as a table and that your dataset represents a large enough sample for investigating the possible use of regression inference and clasification\n",
    "- Explore the data using visualization techniques learned in this course\n",
    "- Formulate what (which attributes) you would like to investigate using a linear regression model\n",
    "- Formulate what question you would like to answer with a classifier based on this dataset. For example: (1) Is this movie a thriller or a comedy? (2) Is this amazon order Fraudulant or not? (3) Does this patient have cancer or not? See section in the book for more details on [Classification](https://www.inferentialthinking.com/chapters/17/Classification.html) \n",
    "- Discuss your choice with you instructor and get approval to get started with section 2\n",
    "\n",
    "*Note 1: If you need guidance on where and how to find a dataset, ask your instructor for help!*\n",
    "\n",
    "*Note 2: Your final project conclusion does not necessarily need to show that you have a good regression model or classifier to make predictions! What is important is your own analysis of its potential and limitations when investigating the dataset for making predictions using these techniques*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1** In the cell below:\n",
    "1. Read in the dataset you chose as a table\n",
    "2. Edit the comment to describe where you found this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Edit this comment to describe where you found this dataset\n",
    "# Load your dataset into a table\n",
    "\n",
    "my_data_raw = ...\n",
    "my_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2:** In the following cell, describe each of the variables in the dataset.  Are they categorical or numerical? How many observations are there?  Add a code cell below this to show how you found the correct number of observations programmatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 1.3:** The dependent or response variable of interest is the variable that we will try to classify later in this project.  This is the variable that should have two levels that will be used in classification later.  \n",
    "\n",
    "For example: (1) Is this movie a thriller or a comedy? (2) Is this amazon order Fraudulent or not? (3) Does this patient have cancer or not? See section in the book for more details on [Classification](https://www.inferentialthinking.com/chapters/17/Classification.html).  \n",
    "\n",
    "In the code cell below, make any necessary adjustments to your data so that the variable is formatted in this way.  Then assign the variable `var` to the column `label` of your table that contains the observations of this variable (note: the label should be a string, so don't forget the quotes!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# If you need to make adjustments to your data so that the variable is formatted in 2 levels add the needed code below, before setting var\n",
    "var = ...\n",
    "var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to investigate our data visually!\n",
    "\n",
    "**Question 1.4:** Think about the numerical variables in the dataset that might be related to each other.  In the cell below, make three different scatter plots that show the relationship between different variables while also displaying how each case is classified.  \n",
    "\n",
    "Use the following line of code:\n",
    "\n",
    "**my_data.scatter(`Column 1`, `Column 2`, group=`label`)**\n",
    "\n",
    "Replace `Column 1` and `Column 2` with the correct column names of numerical variables(features) you would like to investigate. Replace `label` with the column name of the categorical variable you would like to try to classsify.\n",
    "\n",
    "Note: The commented code in the cell below is sample code for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Here is the code placeholder to use, uncomment the line and adjust according to the names if the columns in your dataset:\n",
    "# my_data.scatter(\"Column 1\", \"Column 2\", group=\"label\")\n",
    "\n",
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 1.5** Describe the three plots from the last question.  For each plot, note whether the relationship appears to be linear and whether it is a positive or negative association.  Which of the three plots will you look at for linear regression?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 1.6** In the cell below, formulate the question you would like to try to answer with a classifier that you plan to build."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 1.7** Set the variable **instructor_signed_off** to 'YES' if you have checked in with your instructor during lab hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "instructor_signed_off = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1_7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Regression Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, reduce the table with relevant data that you would like to use to evaluate a linear regression model to make a prediction. In this section, you will evaluate this model and set up a hypothesis test to check if there is true correlation/linear association. You will analyze residuals, confidence interval and prediction lines of best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1** Copy the cell where you loaded the dataset in section 1, reduce the table to only include the relevant data for what you would like to use in your regression model. The table should only have 2 columns of intest since this is simple linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Copy the cell where you loaded the dataset in section 1 and reduce the table to only include the relevant data for linear regression\n",
    "# You may have to clean your data to get rid of outliers\n",
    "\n",
    "my_data = ...\n",
    "my_data = ...\n",
    "my_data.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# As usual, let's investigate our data visually before analyzing it numerically. \n",
    "# Just run this cell to plot the relationship between the 2 attribute/columns.\n",
    "# The scatter plot should look similar to the one you plotted for 1.4. \n",
    "my_data.scatter(0, 1, fit_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.2:**\n",
    "\n",
    "Use the functions given to assign the correlation between the 2 attributes to the variable `cor`.\n",
    "\n",
    "The function `correlation` takes in three arguments, a table `tbl` and the labels of the columns you are finding the correlation between, `col1` and `col2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T09:57:57.365938Z",
     "start_time": "2018-04-04T09:57:57.357879Z"
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def standard_units(arr):\n",
    "    return (arr- np.mean(arr)) / np.std(arr)\n",
    "\n",
    "def correlation(tbl, col1, col2):\n",
    "    r = np.mean(standard_units(tbl.column(col1)) * standard_units(tbl.column(col2)))\n",
    "    return r\n",
    "\n",
    "cor = ...\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you see a correlation between the 2 variables? If in this sample, we found a linear relation between the two variables, would the same be true for the population? Would it be exactly the same linear relation? Could we predict the response of a new individual who is not in our sample?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.3: Writing Hypotheses.**\n",
    "\n",
    "Suppose you think the slope of the true line of best fit for the 2 variables is not zero: that is, there is some correlation/association between them. To test this claim, we can run a hypothesis test! Define the null and alternative hypothesis for this test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 2.4:**\n",
    "\n",
    "Maria says that instead of finding the slope for each resample, we can find the correlation instead, and that we will get the same result. Why is she correct? What is the relationship between slope and correlation?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 2.5:** Define the function `one_resample_r` that performs a bootstrap and finds the correlation between the 2 variables in the resample. `one_resample_r` should take three arguments, a table `tbl` and the labels of the columns you are finding the correlation between, `col1` and `col2`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "manual_problem_id": "crypto_5",
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def one_resample_r(tbl, col1, col2):\n",
    "    ...\n",
    "\n",
    "\n",
    "# Uncomment the line of code below and change `Column 1` and `Column 2` to match your dataset.\n",
    "\n",
    "# one_resample = one_resample_r(my_data, \"Column 1\", \"Column 2\")\n",
    "one_resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.6:**\n",
    "Generate 1000 bootstrapped correlations for the 2 variables, store your results in the array `resampled_correlations`, and plot a histogram of your results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "resampled_correlations = ...\n",
    "...\n",
    "    \n",
    "# Uncomment the line of code below and change column names to match your dataset\n",
    "# Table().with_column(\"Column 1 vs Column 2\", resampled_correlations).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.7:** Calculate a 95% confidence interval for the resampled correlations and assign either `True` or `False` to `reject` if we can reject the null hypothesis or if we cannot reject the null hypothesis using a 5% p-value cutoff.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "otter": {
     "tests": [
      "q2_7"
     ]
    },
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "lower_bound = ...\n",
    "upper_bound = ...\n",
    "reject = ...\n",
    "\n",
    "\n",
    "# Don't change this!\n",
    "print(f\"95% CI: [{lower_bound}, {upper_bound}] , Reject the null: {reject}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to make a prediction for one variable (call this your y variable, or var2) based on the the other (call this your x variable, or var1). First, let's investigate how effective our predictions are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.8:**\n",
    "\n",
    "Calculate the slope and intercept for the line of best fit for the 2 variables. Assign these values to `my_slope`, and `my_intercept`respectively. The function `parameters` returns a two-item array containing the slope and intercept of a linear regression line.\n",
    "\n",
    "*Hint 1: Use the `parameters` function with the arguments specified!*\n",
    "\n",
    "*Hint 2: Remember we're predicting the 2nd variable **based off** a first variable. That should tell you what the `colx` and `coly` arguments you should specify when calling `parameters`.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# DON'T EDIT THE PARAMETERS FUNCTION\n",
    "def parameters(tbl, colx, coly):\n",
    "    x = tbl.column(colx)\n",
    "    y = tbl.column(coly)\n",
    "    \n",
    "    r = correlation(tbl, colx, coly)\n",
    "    \n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "    x_sd = np.std(x)\n",
    "    y_sd = np.std(y)\n",
    "    \n",
    "    slope = (y_sd / x_sd) * r\n",
    "    intercept = y_mean - (slope * x_mean)\n",
    "    return make_array(slope, intercept)\n",
    "\n",
    "my_slope = ...\n",
    "my_intercept = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.9:**\n",
    "\n",
    "Draw a scatter plot of the residuals with the line of best fit for the 2 variables.\n",
    "\n",
    "*Hint: We want to get the predictions for every data point in the dataset*\n",
    "\n",
    "*Hint 2: This question is really involved, try to follow the skeleton code!*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "predicted_var2 = ...\n",
    "residuals_var2 = ...\n",
    "\n",
    "\n",
    "originalTable_with_residuals = ...\n",
    "\n",
    "\n",
    "# Now generate a scatter plot of the residuals!\n",
    "# Uncomment the line of code below and change \"Column 1\" to match variable 1 used in your linear regression analysis\n",
    "#originalTable_with_residuals.scatter(\"Column 1\", \"Residuals\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a [link](https://www.inferentialthinking.com/chapters/15/6/Numerical_Diagnostics.html) to properties of residuals in the textbook that could help out with some questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.10 :**\n",
    "\n",
    "Based on the plot of residuals, do you think linear regression is a good model in this case? Explain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "#### Question 2.11\n",
    "\n",
    "Is the correlation between the residuals and your predictor positive, zero, or negative?  Assign `residual_corr` to either 1, 2 or 3 corresponding to whether the correlation between the residuals and your predictor is positive, zero, or negative.  Hint: it is ok to check this with Python before answering!\n",
    "\n",
    "\n",
    "1. Positive\n",
    "2. Zero\n",
    "3. Negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "residual_corr = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_11\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, Maria wants to predict the 2nd variable based on a chosen first variable x. \n",
    "\n",
    "**Question 2.12:** First, let's identify a value of your choice for x that you want to predict y with and explain in your own words why you chose that value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 2.13:**\n",
    "\n",
    "Define the function `one_resample_prediction` that generates a bootstrapped sample from the `tbl` argument, calculates the line of best fit for `ycol` vs `xcol` for that resample, and predicts a value based on `xvalue`. Then assign the value you chose for x in Question 2.12 to `chosen_var1`.\n",
    "\n",
    "*Hint: Remember you defined the `parameters` function earlier*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def one_resample_prediction(tbl, colx, coly, xvalue):\n",
    "    ...\n",
    "\n",
    "chosen_var1 = ...\n",
    "\n",
    "maria_prediction = ...\n",
    "maria_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_13\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.14:**\n",
    "\n",
    "Assign `resampled_predictions` to be an array that will contain 1000 resampled predictions for the 2nd variable based on `chose_var1` that you picked, and then generate a histogram of it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "export_pdf": true,
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "resampled_predictions = ...\n",
    "\n",
    "...\n",
    "\n",
    "# Don't change/delete the code below in this cell, just run to visualize the distribution\n",
    "Table().with_column(\"Resampled Predictions\", resampled_predictions).hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.15:**\n",
    "\n",
    "Using `resampled_predictions` from Question 2.14, generate a 99% confidence interval for Maria's prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "lower_bound_maria = ...\n",
    "upper_bound_maria = ...\n",
    "\n",
    "\n",
    "# Don't delete/modify the code below in this cell\n",
    "print(f\"99% CI: [{lower_bound_maria}, {upper_bound_maria}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2_15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.16:** Uncomment and change the 2 lines of code underneath the TODOs, with the correct `Column 1` and `Column 2`. Then run the following cell to see a few bootstrapped regression lines, and the predictions they make for your chosen value for `chosen_var1` (picked in question 2.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# You don't need to understand all of what it is doing but you should recognize a lot of the code!\n",
    "lines = Table(['slope','intercept'])\n",
    "\n",
    "x=chosen_var1 # This is the value you picked in question 2.14\n",
    "\n",
    "for i in np.arange(20):\n",
    "    resamp = originalTable_with_residuals.sample(with_replacement=True)\n",
    "    # TODO: change Column 1 and Column 2 in the line below and uncomment\n",
    "    # resample_pars = parameters(resamp, \"Column 1\", \"Column 2\") \n",
    "    slope = resample_pars.item(0)\n",
    "    intercept = resample_pars.item(1)\n",
    "    lines.append([slope, intercept])\n",
    "    \n",
    "lines['prediction at x='+str(x)] = lines.column('slope')*x + lines.column('intercept')\n",
    "# TODO: change Column 1 in the line below and uncomment\n",
    "# xlims = [min(originalTable_with_residuals.column(\"Column 1\")), max(originalTable_with_residuals.column(\"Column 1\"))]\n",
    "left = xlims[0]*lines[0] + lines[1]\n",
    "right = xlims[1]*lines[0] + lines[1]\n",
    "fit_x = x*lines['slope'] + lines['intercept']\n",
    "for i in range(20):\n",
    "    plt.plot(xlims, np.array([left[i], right[i]]), lw=1)\n",
    "    plt.scatter(x, fit_x[i], s=30)\n",
    "plt.ylabel(\"variable 2\"); # You can change the label here to be more descriptive\n",
    "plt.xlabel(\"variable 1\"); # You can change the label here to be more descriptive\n",
    "plt.title(\"Resampled Regression Lines\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 2.17**\n",
    "\n",
    "What are some biases in this dataset that may have affected our analysis? Some questions you can ask yourself are: \"is our sample a simple random sample?\" or \"what kind of data are we using/what variables are we dealing with: are they categorical, numerical, or both (both is something like ordinal data)?\".\n",
    "\n",
    "*Hint: you might want to revisit the beginning of this assignment to reread where your data came from and how the table was generated.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# 3. Classification\n",
    "\n",
    "\n",
    "**Recommended Reading**: \n",
    "\n",
    "* [Classification](https://www.inferentialthinking.com/chapters/17/Classification.html)\n",
    "\n",
    "This part of the project is about k-Nearest Neighbors classification (kNN), and the purpose is to reinforce the basics of this method. You will be using the same dataset you picked in section one to complete this part.\n",
    "\n",
    "We will try to classify our data in 2 classes/groups (labels) based on other variables (features) in our dataset. Go back to question 1.4 and review your answer and your visualization. If it helps copy the code for the visualization below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Let's begin implementing the k-Nearest Neighbors algorithm. Define the `distance` function, which takes in two arguments: an array of numerical features (`arr1`), and a different array of numerical features (`arr2`). The function should return the [Euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between the two arrays. Euclidean distance is often referred to as the straight-line distance formula that you may have learned previously. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def distance(arr1, arr2):\n",
    "    ...\n",
    "\n",
    "# Don't change/delete the code below in this cell\n",
    "distance_example = distance(make_array(1, 2, 3), make_array(4, 5, 6))\n",
    "distance_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardizing the Numerical Variables\n",
    "Before we split the dataset, we need to standardize all numerical variables in our dataset.\n",
    "Just run the code cell below that defines the `standard_units` and `standardize` functions. You will use the `standardize` function in question 3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_units(any_numbers):\n",
    "    \"Convert any array of numbers to standard units.\"\n",
    "    return (any_numbers - np.mean(any_numbers)) / np.std(any_numbers)  \n",
    "\n",
    "def standardize(t):\n",
    "    \"\"\"Return a table in which all columns of t are converted to standard units.\"\"\"\n",
    "    t_su = Table()\n",
    "    for label in t.labels:\n",
    "        t_su = t_su.with_column(label + ' (su)', standard_units(t.column(label)))\n",
    "    return t_su"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset\n",
    "We'll do two different kinds of things with the dataset:\n",
    "\n",
    "1. We'll build a classifier using the data for which we know the associated label; this will teach it to recognize labels of similar coordinate values. This process is known as *training*.\n",
    "2. We'll evaluate or *test* the accuracy of the classifier we build on data we haven't seen before.\n",
    "\n",
    "As discussed in [Section 17.2](https://inferentialthinking.com/chapters/17/2/Training_and_Testing.html#training-and-testing), we want to use separate datasets for training and testing. As such, we split up our one dataset into two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** We will start with the full dataset `my_data_raw` (not the one with just the columns used for regression). The table should contain the variable that will be used in classification, it should look like the table after question 1.3. Next we will:\n",
    "- create a new table `table_only_numerical` with only the numerical variables from `my_data_raw`, \n",
    "- standardize those variables using the `standardize` function defined above and save the standardized table in `table_only_numerical_su`\n",
    "- create a new table `table_su` that includes the standardized numerical variables and the binary column\n",
    "- split our dataset into a training set and a test set:\n",
    "    - first, **shuffle** all the rows in `table_su`\n",
    "    - second, create a training set with the first 75% of the dataset and a test set with the remaining 25% (e.g. if your dataset has 100 rows, 75 rows will be the training set, 25 rows will be the test set). Remember that assignment to each group should be random, so we should shuffle the table first.\n",
    "\n",
    "*Hint: use the* `tbl.take` *function to split up the rows for each table `train` and `test`*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# select only the columns with numerical variables\n",
    "table_only_numerical = ...\n",
    "\n",
    "# Use standardize to standardize the variables in table_only_numerical\n",
    "table_only_numerical_su = ...\n",
    "\n",
    "# Create a new table with the numerical variables in standard units and add the binary column\n",
    "table_su = ...\n",
    "\n",
    "# Shuffle the new table\n",
    "shuffled_table = ...\n",
    "train = ...\n",
    "test = ...\n",
    "\n",
    "print(\"Training set:\\t\",   train.num_rows, \"examples\")\n",
    "print(\"Test set:\\t\",       test.num_rows, \"examples\")\n",
    "train.show(5), test.show(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 K-Nearest Neighbors\n",
    "\n",
    "K-Nearest Neighbors (k-NN) is a classification algorithm.  Given some numerical *attributes* (also called *features*) of an unseen example, it decides whether that example belongs to one or the other of two categories based on its similarity to previously seen examples. Predicting the category of an example is called *labeling*, and the predicted category is also called a *label*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3.** Assign `chosen_features` to an array of column names (strings) of the features (column labels) from the dataset. \n",
    "\n",
    "*Hint: Which of the column names in the table are the features, and which of the column names correspond to the class we're trying to predict?*\n",
    "\n",
    "*Hint: No need to modify any tables, just manually create an array of the feature names!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "chosen_features = ...\n",
    "chosen_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.** Now define the `classify` function. This function should take in a `test_row` from a table like `test` and classify in using the k-Nearest Neighbors based on the correct `features` and the data in `train`. A refresher on k-Nearest Neighbors can be found [here](https://www.inferentialthinking.com/chapters/17/4/Implementing_the_Classifier.html).\n",
    "\n",
    "\n",
    "*Hint 1:* The `distance` function we defined earlier takes in arrays as input, so use the `row_to_array` function we defined for you to convert rows to arrays of features.\n",
    "\n",
    "*Hint 2:* The skeleton code we provided iterates through each row in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def row_to_array(row, features):\n",
    "    \"\"\"Converts a row to an array of its features.\"\"\"\n",
    "    arr = make_array()\n",
    "    for feature in features:\n",
    "        arr = np.append(arr, row.item(feature))\n",
    "    return arr\n",
    "\n",
    "def classify(test_row, k, train, features):\n",
    "    test_row_features_array = row_to_array(test_row, features)\n",
    "    distances = make_array()\n",
    "    for train_row in train.rows:\n",
    "        train_row_features_array = ...\n",
    "        row_distance = ...\n",
    "        distances = ...\n",
    "    train_with_distances = ...\n",
    "    nearest_neighbors = ...\n",
    "    most_common_label = ...\n",
    "    ...\n",
    "\n",
    "# Don't modify/delete the code below\n",
    "first_test = classify(test.row(0), 5, train, chosen_features)\n",
    "first_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating your classifier\n",
    "\n",
    "Now that we have a way to use this classifier, let's focus on the 3 Nearest Neighbors and see how accurate it is on the whole test set.\n",
    "\n",
    "**Question 3.5.** Define the function `three_classify` that takes a `row` from `test` as an argument and classifies the row based on using 3-Nearest Neighbors. Use this function to find the `accuracy` of a 3-NN classifier on the `test` set. `accuracy` should be a proportion (not a percentage) of the test data that were correctly predicted.\n",
    "\n",
    "\n",
    "*Hint: You should be using a function you just created!*\n",
    "\n",
    "*Note: Usually before using a classifier on a test set, we'd classify first on a \"validation\" set, which we then can modify our training set again if need be, before actually testing on the test set. You donâ€™t need to do that for this question, but please keep this in mind for future courses.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "def three_classify(row):\n",
    "    ...\n",
    "\n",
    "test_with_prediction = ...\n",
    "labels_correct = ...\n",
    "accuracy = ...\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Question 3.6.** An important part of evaluating your classifiers is figuring out where they make mistakes. Assign the name `test_correctness` to the test_with_prediction table with an additional column `'Was correct'`. The last column should contain `True` or `False` depending on whether or not our classifier classified correctly.\n",
    "*Note:* You can either include all of the columns from the test_with_prediction table or just the columns representing the features used by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Feel free to use multiple lines of code\n",
    "# but make sure to assign test_correctness to the proper table!\n",
    "test_correctness = ...\n",
    "    ...\n",
    "test_correctness.sort('Was correct', descending = False).show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** Do you see a pattern in the rows that your classifier misclassifies? In two sentences or less, describe any patterns you see in the results or any other interesting findings from the table above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 3.8.** Why do we divide our data into a training and test set? What is the point of a test set, and why do we only want to use the test set once? Explain your answer in 3 sentences or less. \n",
    "\n",
    "*Hint:* Check out this [section](https://inferentialthinking.com/chapters/17/5/Accuracy_of_the_Classifier.html) in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 3.9.** Why do we use an odd-numbered `k` in k-NN? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "At this point, you've gone through one cycle of classifier design.  Let's summarize the steps:\n",
    "1. From available data, select test and training sets.\n",
    "2. Choose an algorithm you're going to use for classification.\n",
    "3. Identify some features.\n",
    "4. Define a classifier function using your features and the training set.\n",
    "5. Evaluate its performance (the proportion of correct classifications) on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explorations\n",
    "Now that you know how to evaluate a classifier, it's time to build a better one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.1:**\n",
    "\n",
    "Develop a classifier with better test-set accuracy than `three_classify`.  Your new function should have the same arguments as `three_classify` and return a classification.  Name it `another_classifier`. Then, check your accuracy using code from earlier.\n",
    "\n",
    "You can use more or different features, or you can try different values of `k`. (Of course, you still have to use `train` as your training set!) \n",
    "\n",
    "**Make sure to create new variable names where needed, don't reassign any previously used variables here**, such as `accuracy` from the section 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to remember what your accuracy was in the first attempt.\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Feel free to add or change this array to improve your classifier\n",
    "# Note that you can either use the original chosen_features or create a new list below\n",
    "\n",
    "new_features = ...\n",
    "\n",
    "def another_classifier(row):\n",
    "    ...\n",
    "\n",
    "new_test_with_prediction = ...\n",
    "new_labels_correct = ...\n",
    "new_accuracy = ...\n",
    "new_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Now that we looked at the accuracy, let's analyze correctness of your new classifier\n",
    "# Use this coding cell to explore your data/ this cell will not be graded\n",
    "# You are free to use as many lines of code as you would like\n",
    "# you could look at a sorted table again just like in 3.6!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.2** \n",
    "\n",
    "Did your new classifier work better? Do you see a pattern in the mistakes your new classifier makes? What about in the improvement from your first classifier to the second one? Describe in two sentences or less.\n",
    "\n",
    "**Hint:** You may not be able to see a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 4.3**\n",
    "\n",
    "Briefly describe what you tried to improve your classifier. Any other ideas on how you could make a better classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 4.4:**\n",
    "Misclassification and errors in classifiers happens all the time and can really affect an individual. When applying machine learning and building classifiers, we all need to do our best to minimize misclassification and make sure we are transparent about the accuracies of what we built. Have you ever experienced something like this in real life before, where something was classified incorrectly? If not, can you think of an example where misclassification could really affect an individual? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Question 4.5:**\n",
    "We hope you enjoyed the project! You made it to the concluding question. \n",
    "\n",
    "In a couple of sentences, share what you learned about your dataset while exploring its potential for prediction and classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "**Congratulations**: You're DONE with the final project notebook! Nice work. \n",
    "Time to submit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1_1": {
     "name": "q1_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(my_data_raw) == Table\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> my_data_raw.num_columns >= 6\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> my_data_raw.num_rows >= 100\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_3": {
     "name": "q1_3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(my_data_raw.column(var)) == np.ndarray\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> my_data_raw.group(var).num_rows == 2\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> my_data_raw.group(var).column('count').item(0) / my_data_raw.num_rows >= 0.1\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> my_data_raw.group(var).column('count').item(1) / my_data_raw.num_rows >= 0.1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1_7": {
     "name": "q1_7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> instructor_signed_off == 'YES'\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_1": {
     "name": "q2_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> my_data.num_columns == 2\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> type(my_data.column(0).item(0)) != str and type(my_data.column(0).item(0)) != bool\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_11": {
     "name": "q2_11",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> residual_corr in [1, 2, 3]\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_13": {
     "name": "q2_13",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(maria_prediction) in set([float, np.float32, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_15": {
     "name": "q2_15",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> all([type(lower_bound_maria) in set([float, np.float32, np.float64]), type(upper_bound_maria) in set([float, np.float32, np.float64])])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_2": {
     "name": "q2_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> -1 <= cor <= 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_5": {
     "name": "q2_5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> -1 <= one_resample <= 1\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_6": {
     "name": "q2_6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(resampled_correlations) == np.ndarray\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> len(resampled_correlations) == 1000\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2_7": {
     "name": "q2_7",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_1": {
     "name": "q3_1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> type(distance_example) in set([float, np.float32, np.float64])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(distance_example, 5.196152422706632)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3_2": {
     "name": "q3_2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> table_test = shuffled_table.drop(var)\n>>> standardized = True\n>>> for i in range(table_test.num_columns):\n...     if abs(np.average(table_test.column(i))) > 10 ** (-12):\n...         standardized = False\n...         break\n>>> standardized\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> train.num_rows == round(75 * my_data_raw.num_rows / 100, 0)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> test.num_rows == round(25 * my_data_raw.num_rows / 100, 0)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> train.num_rows + test.num_rows == my_data_raw.num_rows\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
